# attention_all (NLP)
各种attention的keras实现（暂4种）

1 soft-attention-alignment

2 co-attention

3 层级attention

4 multi-head self-attention
