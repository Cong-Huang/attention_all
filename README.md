# attention_all (NLP)
各种attention的keras实现

1 soft-attention-alignment
2 co-attention
3 层级attention
4 multi-head self-attention
